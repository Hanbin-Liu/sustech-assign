---
title: "Statistical Calculation and Software"
author: "Assignment 2"
date: "Hanbin Liu 11912410"
output:
  #html_document
  pdf_document:
    keep_tex: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
setwd("C:/Users/HP/Desktop/R_project/R_assignments")
library(ggplot2)
library(car)
```

## 2.1

```{r message=FALSE}
library(UsingR)
data(kid.weights)
```

### (a)
```{r}
ggplot(kid.weights, aes(x = gender, y = height, fill = gender)) +
  geom_boxplot() + xlab("gender") + ylab("height") +
  ggtitle("Boxplots for the heights of two genders of children") +
  theme(plot.title = element_text(hjust = 0.5),
        text = element_text(size = 14, family = "serif")) +
  scale_fill_manual(values = c("#999999", "#E69F00"))
```
```{r}
# unknown variance
x <- kid.weights$height
n <- length(x)
t <- (sqrt(n) * (mean(x) - 36)) / sd(x)
pval <- 2 * pt(t, n - 1, lower.tail = F)
name <- c("Test statistics: t", "df", "t(0.025,249)", "p-value")
value <-
  c((sqrt(n) * (mean(x) - 36)) / sd(x), n - 1, qt(0.975, n - 1), pval)
data.frame(name, value)
```
We cannot reject $H_0$ with unknown variance.

```{r}
# known variance
pval <- 2 * pnorm((sqrt(n) * (mean(x) - 36)) / sd(x), lower.tail = F)
name <- c("Test statistic: z", "z_0.025", "p-value")
value <- c((sqrt(n) * (mean(x) - 36)) / sd(x), qnorm(0.975), pval)
data.frame(name, value)
```
We cannot reject $H_0$ if the variance is known to be the current sample variance.

### (b)
We have 
\begin{equation*}
\sup \limits_{\theta \in \Theta_0} L(\theta \mid \mathbf{X}) = \frac{1}{( 2\pi \hat \sigma_1^2)^{\frac{n}{2}}} \exp\Big\{ -\frac{1}{2\hat \sigma_1^2} \sum_{i=1}^n (X_i - \mu_0)^2 \Big\},
\end{equation*} 
and 
\begin{equation*}
\sup \limits_{\theta \in \Theta} L(\theta \mid \mathbf{X}) = \frac{1}{( 2\pi \hat \sigma_2^2)^{\frac{n}{2}}}\exp\Big\{ -\frac{1}{2\hat \sigma_2^2} \sum_{i=1}^n (X_i - \bar X)^2 \Big\},
\end{equation*} 
where 
\begin{equation*}
\hat \sigma_1^2 = \frac{1}{n}\sum_{i=1}^n (X_i - \mu_0)^2, \quad \hat \sigma_2^2 = \frac{1}{n}\sum_{i=1}^n (X_i - \bar X)^2.
\end{equation*} Then the likelihood ratio is given by \begin{equation*}
\lambda(\mathbf{X}) = \frac{ \sup \limits_{\theta \in \Theta_0} L(\theta \mid \mathbf{X}) }{ \sup \limits_{\theta \in \Theta} L(\theta \mid \mathbf{X}) } = (\frac{\hat \sigma_2^2 }{\hat \sigma_1^2 })^{\frac{n}{2}} = \Bigg[  \frac{ \sum_{i=1}^n (X_i - \bar X)^2 }{ \sum_{i=1}^n (X_i - \mu_0)^2 } \Bigg]^{\frac{n}{2}}.
\end{equation*}
Note that 
\begin{equation*}
  \sum_{i=1}^n (X_i - \mu_0)^2 = \sum_{i=1}^n (X_i - \bar X)^2 + n(\bar X - \mu_0)^2.
\end{equation*}
It then follows that 
\begin{equation*}
  \lambda(\mathbf{X}) = \Bigg( \frac{1}{1 + \frac{n(\bar X-\mu_0)^2}{\sum_{i=1}^n (X_i - \bar X)^2}} \Bigg)^{\frac{n}{2}}.
\end{equation*}
Then 
\begin{equation*}
  \Bigg( \frac{1}{1 + \frac{n(\bar X-\mu_0)^2}{\sum_{i=1}^n (X_i - \bar X)^2}} \Bigg)^{\frac{n}{2}} \leq k
\end{equation*}
is equivalent to 
\begin{equation*}
  \frac{n(\bar X-\mu_0)^2}{\sum_{i=1}^n (X_i - \bar X)^2} \geq  c \Longleftrightarrow  \frac{n(\bar X - \mu_0)^2}{S^2 } \geq (n-1)c = c^*.
\end{equation*}
Under $H_0$, $T = \frac{\sqrt{n}(\bar X - \mu_0)}{S} \sim t(n-1).$ Hence, 
\begin{equation*}
  \alpha = \Pr(T^2 \geq c^* \mid H_0),
\end{equation*}
which implies that $\sqrt{c^*} = t_{\frac{\alpha}{2}}(n-1).$ Therefore, the testing procedure is 
\begin{equation*}
  {\rm reject}\ H_0\ {\rm if} \Bigg\{ \Bigg| \frac{\sqrt{n}(\bar X - \mu_0)}{S} \Bigg| \geq  t_{\frac{\alpha}{2}}(n-1) \Bigg\}
\end{equation*}
```{r}
x <- kid.weights$height[kid.weights$gender == 'M']
n <- length(x)
# likelihood ratio test
pval <-
  2 * pt((sqrt(n) * (mean(x) - 36)) / sd(x), n - 1, lower.tail = F)
name <- c("Test statistic: t", "df", "t(0.025,120)", "p-value")
value <-
  c((sqrt(n) * (mean(x) - 36)) / sd(x), n - 1, qt(0.975, n - 1), pval)
data.frame(name, value)
```
We cannot reject $H_0$ that the mean is 36 at $\alpha = 0.05$ level of significance.
```{r}
# one-sample t test
t.test(x, mu = 36)
```
We cannot reject $H_0$ that the mean of male is equal to the mean of female at $\alpha = 0.05$ level of significance. The results are the same.

### (c)
Normality assumption:
```{r}
t.test(height ~ gender, data = kid.weights, alternative = "less")
```
We cannot reject $H_0$ that the height of the male and female have the same mean value at $\alpha = 0.05$ level of significance.

Non-parametric Test:
```{r}
wilcox.test(height ~ gender, data = kid.weights)
```
We cannot reject $H_0$ that the height of the male and female have the same mean value at $\alpha = 0.05$ level of significance.

### (d)
```{r message=FALSE, warnings=FALSE}
male <- kid.weights$height[kid.weights$gender == 'M']
female <- kid.weights$height[kid.weights$gender == 'F']
# Siegel-Tukey test (the medians of two samples are close to each other)
library(ACSWR)
siegel.tukey(male, female)
# Kolmogorov-Smirnov Test
ks.test(male, female)
```
We cannot reject $H_0$ that the spread of height for the male and female are the same.


## 2.2
```{r}
Carseats <- read.csv("Carseats.csv")
```

### (a)
```{r}
ggplot(Carseats, aes(sample = Sales)) +
  stat_qq(colour = '#999999', pch = 1) +
  stat_qq_line(colour = '#E69F00') +
  ggtitle("Normal Q-Q Plot") +
  theme(plot.title = element_text(hjust = 0.5),
        text = element_text(size = 14, family = "serif")) +
  xlab("Theoretical Quantiles") +
  ylab("Sample Quantiles")
```

```{r}
x <- Carseats$Sales
ks.test(x, "pnorm", mean = mean(x), sd = sd(x))
```
We cannot reject $H_0$ that Sales follow normal distribution.

### (b)
```{r}
model <- lm(Sales ~ Price + Advertising + Age + Urban, data = Carseats)
summary(model)
```

### (c)
```{r}
coefficients(model)
```
The coefficient for the intercept is equal to 15.99282333. This means that for a sample with 'Price', 'Advertising', 'Age' are 0 and 'Urban' is 'No', the average expected sales is 15.99282333. It’s important to note that the regression coefficient for the intercept is only meaningful if it’s reasonable that all of the predictor variables in the model can actually be equal to zero.


The coefficient for 'Price' is -0.05804694. This means that, on average, each additional 'Price' is associated with a decrease of 0.05804694 for the 'Sales', assuming other predictor variables are held constant.

The coefficient for 'Advertising' is 0.12305077. This means that, on average, each additional 'Advertising' is associated with an increase of 0.12305077 for the 'Sales', assuming other predictor variables are held constant.

The coefficient for 'Age' is -0.04886540. This means that, on average, each additional 'Age' is associated with a decrease of 0.04886540 for the 'Sales', assuming other predictor variables are held constant.

The coefficient for 'UrbanYes' is 0.02018579. This means that, on average, a sample whose 'Urban' is 'Yes' has a higher 'Sales' compared to a sample whose 'Urban' is 'No' and the difference is 0.02018579, assuming other predictor variables are held constant.


### (d)
The equation form for the model is 
\begin{equation*}
{\rm Sales} = 
\begin{cases}
 15.992823 - 0.058047*{\rm Price} + 0.123051*{\rm Advertising} - 0.048865*{\rm Age} ,\ {\rm if}\ {\rm Urban}\ =\ {\rm No},\\
 16.013009 - 0.058047*{\rm Price} + 0.123051*{\rm Advertising} - 0.048865*{\rm Age} ,\ {\rm if}\ {\rm Urban}\ =\ {\rm Yes}.
\end{cases}
\end{equation*}

### (e)
```{r}
summary(model)
```
We can reject the null hypothesis $H_0:\beta_j = 0$ for j = 0,1,2,3.

### (f)
```{r}
model2 <- lm(Sales ~ Price + Advertising + Age, data = Carseats)
summary(model2)
```

### (g)
Model in (b) has a $R^2=0.3596,$ and adjusted $R^2 = 0.3531$ while model in (f) has a $R^2 = 0.3595$ and adjusted $R^2=0.3547.$ Their R-squared and adjusted R-squared value are close to each other, however, model in (f) involves fewer variables and has a larger adjusted R-squared value. Therefore, model in (f) is better than the model in (b). But since their adjusted R-squared values are all less than 0.36, these two models both have relatively non-ideal performance. 

Model diagnostic:
```{r}
par(mfrow = c(2, 2))
plot(model)
plot(model2)
par(mfrow = c(1, 1))
```

Normality:
```{r}
qqPlot(model)
qqPlot(model2)
```

Independence:
```{r}
durbinWatsonTest(model)
durbinWatsonTest(model2)
```

Linearity:
```{r}
crPlots(model)
crPlots(model2)
```

Homoscedasticity:
```{r}
ncvTest(model)
spreadLevelPlot(model)
#
ncvTest(model2)
spreadLevelPlot(model2)
```

### (h)
```{r}
confint(model2)
```

### (i)
```{r}
# outilier
outlierTest(model2)
```

```{r}
# high leverage observations
hat.plot <- function(fit) {
  p <- length(coefficients(fit))
  n <- length(fitted(fit))
  plot(hatvalues(fit), main = "Index Plot of Hat Values")
  abline(h = c(2, 3) * p / n,
         col = "red",
         lty = 2)
  identify(1:n, hatvalues(fit), names(hatvalues(fit)))
}
hat.plot(model2)
```
There are no outliers but high leverage observations in the model.

### (j)
```{r}
attach(Carseats)
x <- Sales[Urban == 'Yes']
y <- Sales[Urban == 'No']

group <- c("Urban", "Non-urban")
mean <- c(mean(x), mean(y))
data.frame(group, mean)
```
Likelihood ratio test:
```{r}
# method 1
n1 <- length(x)
n2 <- length(y)
Sp <- sqrt(((n1 - 1) * var(x) + (n2 - 1) * var(y)) / (n1 + n2 - 2))
t <- abs(mean(x) - mean(y)) / (sqrt(1 / n1 + 1 / n2) * Sp)
pval <- 2 * pt(t, n1 + n2 - 1, lower.tail = F)
name <- c("Test statistic: t", "df", "t(0.025,398)", "p-value")
value <- c(t, n1 + n2 - 2, qt(0.975, n1 + n2 - 2), pval)
data.frame(name, value)
```
```{r}
# method 2: set var.equal = TRUE in t.test()
t.test(Sales ~ Urban, var.equal = TRUE)
```
We cannot reject $H_0$ that the two samples have the same mean.

Mann-Whitney test:
```{r}
wilcox.test(Sales ~ Urban, Carseats)
```
We cannot reject $H_0$ that the two samples have the same mean.

```{r}
paste(c("n1:", "n2:"), c(n1, n2))
```
We cannot use the Wilcoxon’s Signed-Rank test since they have different size.

### (k)
```{r}
# stepwise methods
fit <- lm(Sales ~ ., data = Carseats)
stepAIC(fit, direction = "both")
```
```{r}
# all-subsets regression
library(leaps)
leaps <- regsubsets(Sales ~ ., data = Carseats)
plot(leaps, scale = "adjr2")

library(car)
subsets(
  leaps,
  statistic = "cp",
  main = "Cp Plot for All Subsets Regression",
  legend = c(8.6, 3400)
)
abline(1, 1, lty = 2, col = "red")
```

### (l)
```{r}
relweights <- function(fit, ...) {
  R <- cor(fit$model)
  nvar <- ncol(R)
  rxx <- R[2:nvar, 2:nvar]
  rxy <- R[2:nvar, 1]
  svd <- eigen(rxx)
  evec <- svd$vectors
  ev <- svd$values
  delta <- diag(sqrt(ev))
  lambda <- evec %*% delta %*% t(evec)
  lambdasq <- lambda ^ 2
  beta <- solve(lambda) %*% rxy
  rsquare <- colSums(beta ^ 2)
  rawwgt <- lambdasq %*% beta ^ 2
  import <- (rawwgt / rsquare) * 100
  import = as.data.frame(import)
  row.names(import) = names(fit$model[2:nvar])
  names(import) = "weights"
  import = import[order(import), 1, drop = FALSE]
  dotchart(
    import$weights,
    labels = row.names(import),
    xlab = " % of R-Square",
    pch = 19,
    main = "Relative Importance of Predictor Variables",
    sub = paste("Total R-Square=", round(rsquare, digits = 3)),
    ...
  )
  return(import)
}
```
```{r}
temp <- Carseats
temp$ShelveLocGood <- 0
temp$ShelveLocMedium <- 0
temp$UrbanYes <- 0
temp$USYes <- 0
temp$ShelveLocGood[temp$ShelveLoc == "Good"] <- 1
temp$ShelveLocMedium[temp$ShelveLoc == "Medium"] <- 1
temp$UrbanYes[temp$Urban == "Yes"] <- 1
temp$USYes[temp$US == "Yes"] <- 1
```
```{r}
fit <-
  lm(
    Sales ~ X + CompPrice + Income + Advertising + Population + Price + Age +
      Education + ShelveLocGood + ShelveLocMedium + UrbanYes + USYes,
    data = temp
  )
relweights(fit, col = "blue")
```
The results are compatible with the results in (k).

```{r}
detach(Carseats)
```

## 2.3
```{r}
weekly <- read.csv("weekly.csv")
```

### (a)
```{r}
summary(weekly)
```

```{r}
plot(weekly)
```
We can see that some statistics of 'Lags' as well as 'Today' are very similar to each other. And most data should be concentrated in a small interval except for some outliers. No. of 'Down' days is slightly smaller than 'Up' days. Volume is increasing by the year.

### (b)
```{r}
# Up -- 1; Down -- 0
weekly$y[weekly$Direction == 'Up'] <- 1
weekly$y[weekly$Direction == 'Down'] <- 0
weekly$y <- factor(weekly$y, levels = c(0, 1), labels = c(0, 1))
fit <-
  glm(
    y ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
    family = binomial(link = "logit"),
    data = weekly
  )
summary(fit)
```
There is a predictor that appears to be statistically significant. Lag2

### (c)
```{r}
a <- exp(predict(fit))
pai <- a / (1 + a)
pai[pai > 0.5] <- 1
pai[pai < 0.5] <- 0
temp <- data.frame(weekly$y, pai)
# assume 'Up' -- 1 is positive
TP <- length(which(temp[1] == 1 & temp[2] == 1))
FN <- length(which(temp[1] == 1 & temp[2] == 0))
FP <- length(which(temp[1] == 0 & temp[2] == 1))
TN <- length(which(temp[1] == 0 & temp[2] == 0))
# confusion matrix
data.frame(
  predict.up = c(TP, FP),
  predict.down = c(FN, TN),
  row.names = c('true.up', 'true.down')
)
# overall fraction of correct predictions
frac <- (TP + TN) / (TP + FN + FP + TN)
sprintf('overall fraction of correct predictions:   %f', frac)
```
Assume 'Up' is 'positive', associating with 1 and 'Down' is 'negative', associating with 0. Then from the confusion matrix, we have 

Type I error rate = FP/(FP+TN) = 430/(430+54) = 88.84%

Type II error rate = FN/(FN+TP) =48/(48+557) = 7.93%

There are more Type I mistakes. However, this conclusion is opposite if 'Down' is 'positive'.

### (d)
```{r}
fit <-
  glm(y ~ Lag2, data = weekly[weekly$Year <= 2009, ], family = binomial())

a <- exp(predict(fit, newdata = weekly[weekly$Year == 2010, ]))
pai <- a / (1 + a)
pai[pai > 0.5] <- 1
pai[pai < 0.5] <- 0
temp <- data.frame(weekly[weekly$Year == 2010, ]$y, pai)
# assume 'Up' -- 1 is positive
TP <- length(which(temp[1] == 1 & temp[2] == 1))
FN <- length(which(temp[1] == 1 & temp[2] == 0))
FP <- length(which(temp[1] == 0 & temp[2] == 1))
TN <- length(which(temp[1] == 0 & temp[2] == 0))
# confusion matrix
data.frame(
  predict.up = c(TP, FP),
  predict.down = c(FN, TN),
  row.names = c('true.up', 'true.down')
)
# overall fraction of correct predictions
frac <- (TP + TN) / (TP + FN + FP + TN)
sprintf('overall fraction of correct predictions:   %f', frac)
```



